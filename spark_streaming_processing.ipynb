{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Streaming application using Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DoubleType, LongType, TimestampType\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code to create a SparkSession with the following requirements: 1) use four cores with a proper application name; 2) Melbourne timezone; 3) a checkpoint location has been set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"assignment2ab\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"Australia/Melbourne\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"checkpoint/ck\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Similar to assignment 2A, write code to define the data schema for the data files, following the data types suggested in the metadata file. Load the static datasets(previous_application_static and value_dict) into data frames. (You can reuse your code from 2A.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code use from previous assignment\n",
    "prev_data_schema = StructType([\n",
    "    StructField(\"id_app\", IntegerType(), True),\n",
    "    StructField(\"contract_type\", IntegerType(), True),\n",
    "    StructField(\"amt_annuity\", FloatType(), True),\n",
    "    StructField(\"amt_application\", FloatType(), True),\n",
    "    StructField(\"amt_credit\", FloatType(), True),\n",
    "    StructField(\"amt_down_payment\", FloatType(), True),\n",
    "    StructField(\"amt_goods_price\", FloatType(), True),\n",
    "    StructField(\"hour_appr_process_start\", IntegerType(), True),\n",
    "    StructField(\"rate_down_payment\", FloatType(), True),\n",
    "    StructField(\"rate_interest_primary\", FloatType(), True),\n",
    "    StructField(\"rate_interest_privileged\", FloatType(), True),\n",
    "    StructField(\"name_cash_loan_purpose\", StringType(), True),\n",
    "    StructField(\"name_contract_status\", StringType(), True),\n",
    "    StructField(\"days_decision\", IntegerType(), True),\n",
    "    StructField(\"name_payment_type\", StringType(), True),\n",
    "    StructField(\"code_reject_reason\", StringType(), True),\n",
    "    StructField(\"name_type_suite\", StringType(), True),\n",
    "    StructField(\"name_client_type\", StringType(), True),\n",
    "    StructField(\"name_goods_category\", StringType(), True),\n",
    "    StructField(\"name_portfolio\", StringType(), True),\n",
    "    StructField(\"name_product_type\", StringType(), True),\n",
    "    StructField(\"channel_type\", StringType(), True),\n",
    "    StructField(\"sellerplace_area\", IntegerType(), True),\n",
    "    StructField(\"name_seller_industry\", StringType(), True),\n",
    "    StructField(\"cnt_payment\", FloatType(), True),\n",
    "    StructField(\"name_yield_group\", StringType(), True),\n",
    "    StructField(\"product_combination\", StringType(), True),\n",
    "    StructField(\"days_first_drawing\", FloatType(), True),\n",
    "    StructField(\"days_first_due\", FloatType(), True),\n",
    "    StructField(\"days_last_due_1st_version\", FloatType(), True),\n",
    "    StructField(\"days_last_due\", FloatType(), True),\n",
    "    StructField(\"days_termination\", FloatType(), True),\n",
    "    StructField(\"nflag_insured_on_approval\", FloatType(), True),\n",
    "    StructField(\"id\",IntegerType() , True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = spark.read.csv(\"previous_application_static.csv\",header = True, schema=prev_data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_dic_data = spark.read.csv(\"value_dict.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the Kafka topic from the producer in Task 1, read the streaming data with Spark Streaming, assuming all data comes in the String format. Except for the 'ts' column, you shall receive it as an Int type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'test'\n",
    "#configuration\n",
    "hostip = \"host.docker.internal\"\n",
    "\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f\"{hostip}:9092\") \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the stream data\n",
    "query1 = df\\\n",
    "            .writeStream\\\n",
    "            .outputMode(\"append\")\\\n",
    "            .format(\"console\")\\\n",
    "            .trigger(processingTime= \"5 seconds\")\\\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.selectExpr(\"CAST(value AS STRING)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = df\\\n",
    "            .writeStream\\\n",
    "            .outputMode(\"append\")\\\n",
    "            .format(\"console\")\\\n",
    "            .trigger(processingTime= \"5 seconds\")\\\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_data_schema = ArrayType(StructType([\n",
    "    StructField(\"id_app\", StringType(), True),\n",
    "    StructField(\"target\", StringType(), True),\n",
    "    StructField(\"contract_type\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"own_car\", StringType(), True),\n",
    "    StructField(\"own_property\", StringType(), True),\n",
    "    StructField(\"num_of_children\", StringType(), True),\n",
    "    StructField(\"income_total\", StringType(), True),\n",
    "    StructField(\"amt_credit\", StringType(), True),\n",
    "    StructField(\"amt_annuity\", StringType(), True),\n",
    "    StructField(\"amt_goods_price\", StringType(), True),\n",
    "    StructField(\"income_type\", StringType(), True),\n",
    "    StructField(\"education_type\", StringType(), True),\n",
    "    StructField(\"family_status\", StringType(), True),\n",
    "    StructField(\"housing_type\", StringType(), True),\n",
    "    StructField(\"region_population_relative\", StringType(), True),\n",
    "    StructField(\"days_birth\", StringType(), True),\n",
    "    StructField(\"days_employed\", StringType(), True),\n",
    "    StructField(\"own_car_age\", StringType(), True),\n",
    "    StructField(\"flag_mobile\", StringType(), True),\n",
    "    StructField(\"flag_emp_phone\", StringType(), True),\n",
    "    StructField(\"flag_work_phone\", StringType(), True),\n",
    "    StructField(\"flag_cont_mobile\", StringType(), True),\n",
    "    StructField(\"flag_phone\", StringType(), True),\n",
    "    StructField(\"flag_email\", StringType(), True),\n",
    "    StructField(\"occupation_type\", StringType(), True),\n",
    "    StructField(\"cnt_fam_members\", StringType(), True),\n",
    "    StructField(\"weekday_app_process_start\", StringType(), True),\n",
    "    StructField(\"hour_app_process_start\", StringType(), True),\n",
    "    StructField(\"organization_type\", StringType(), True),\n",
    "    StructField(\"credit_score_1\", StringType(), False),\n",
    "    StructField(\"credit_score_2\", StringType(), False),\n",
    "    StructField(\"credit_score_3\", StringType(), False),\n",
    "    StructField(\"days_last_phone_change\", StringType(), True),\n",
    "    StructField(\"amt_credit_req_last_hour\", StringType(), True),\n",
    "    StructField(\"amt_credit_req_last_day\",StringType(), True),\n",
    "    StructField(\"amt_credit_req_last_week\", StringType(), True),\n",
    "    StructField(\"amt_credit_req_last_month\", StringType(), True),\n",
    "    StructField(\"amt_credit_req_last_quarter\", StringType(), True),\n",
    "    StructField(\"amt_credit_req_last_year\", StringType(), True),\n",
    "    StructField(\"ts\", IntegerType(), True)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.select(F.from_json(F.col(\"value\").cast(\"string\"),app_data_schema).alias('parsed_value'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Then, transform the streaming data format into proper types following the metadata file schema, similar to assignment 2A. Perform the following tasks:  \n",
    "a) For the 'ts' column, convert it to the timestamp format, we will use it as event_time.  \n",
    "b) If the data is late for more than 1 minute, discard it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_formatted = df.select(\n",
    "    F.col(\"unnested_value.id_app\").cast(IntegerType()).alias(\"id_app\"),\n",
    "    F.col(\"unnested_value.target\").cast(IntegerType()).alias(\"target\"),\n",
    "    F.col(\"unnested_value.contract_type\").cast(IntegerType()).alias(\"contract_type\"),\n",
    "    F.col(\"unnested_value.gender\").cast(StringType()).alias(\"gender\"),\n",
    "    F.col(\"unnested_value.own_car\").cast(StringType()).alias(\"own_car\"),\n",
    "    F.col(\"unnested_value.own_property\").cast(StringType()).alias(\"own_property\"),\n",
    "    F.col(\"unnested_value.num_of_children\").cast(IntegerType()).alias(\"num_of_children\"),\n",
    "    F.col(\"unnested_value.income_total\").cast(FloatType()).alias(\"income_total\"),\n",
    "    F.col(\"unnested_value.amt_credit\").cast(FloatType()).alias(\"amt_credit\"),\n",
    "    F.col(\"unnested_value.amt_annuity\").cast(FloatType()).alias(\"amt_annuity\"),\n",
    "    F.col(\"unnested_value.amt_goods_price\").cast(FloatType()).alias(\"amt_goods_price\"),\n",
    "    F.col(\"unnested_value.income_type\").cast(IntegerType()).alias(\"income_type\"),\n",
    "    F.col(\"unnested_value.education_type\").cast(IntegerType()).alias(\"education_type\"),\n",
    "    F.col(\"unnested_value.family_status\").cast(IntegerType()).alias(\"family_status\"),\n",
    "    F.col(\"unnested_value.housing_type\").cast(IntegerType()).alias(\"housing_type\"),\n",
    "    F.col(\"unnested_value.region_population_relative\").cast(FloatType()).alias(\"region_population_relative\"),\n",
    "    F.col(\"unnested_value.days_birth\").cast(IntegerType()).alias(\"days_birth\"),\n",
    "    F.col(\"unnested_value.days_employed\").cast(IntegerType()).alias(\"days_employed\"),\n",
    "    F.col(\"unnested_value.own_car_age\").cast(FloatType()).alias(\"own_car_age\"),\n",
    "    F.col(\"unnested_value.flag_mobile\").cast(IntegerType()).alias(\"flag_mobile\"),\n",
    "    F.col(\"unnested_value.flag_emp_phone\").cast(IntegerType()).alias(\"flag_emp_phone\"),\n",
    "    F.col(\"unnested_value.flag_work_phone\").cast(IntegerType()).alias(\"flag_work_phone\"),\n",
    "    F.col(\"unnested_value.flag_cont_mobile\").cast(IntegerType()).alias(\"flag_cont_mobile\"),\n",
    "    F.col(\"unnested_value.flag_phone\").cast(IntegerType()).alias(\"flag_phone\"),\n",
    "    F.col(\"unnested_value.flag_email\").cast(IntegerType()).alias(\"flag_email\"),\n",
    "    F.col(\"unnested_value.occupation_type\").cast(IntegerType()).alias(\"occupation_type\"),\n",
    "    F.col(\"unnested_value.cnt_fam_members\").cast(FloatType()).alias(\"cnt_fam_members\"),\n",
    "    F.col(\"unnested_value.weekday_app_process_start\").cast(StringType()).alias(\"weekday_app_process_start\"),\n",
    "    F.col(\"unnested_value.hour_app_process_start\").cast(IntegerType()).alias(\"hour_app_process_start\"),\n",
    "    F.col(\"unnested_value.organization_type\").cast(IntegerType()).alias(\"organization_type\"),\n",
    "    F.col(\"unnested_value.credit_score_1\").cast(FloatType()).alias(\"credit_score_1\"),\n",
    "    F.col(\"unnested_value.credit_score_2\").cast(FloatType()).alias(\"credit_score_2\"),\n",
    "    F.col(\"unnested_value.credit_score_3\").cast(FloatType()).alias(\"credit_score_3\"),\n",
    "    F.col(\"unnested_value.days_last_phone_change\").cast(FloatType()).alias(\"days_last_phone_change\"),\n",
    "    F.col(\"unnested_value.amt_credit_req_last_hour\").cast(FloatType()).alias(\"amt_credit_req_last_hour\"),\n",
    "    F.col(\"unnested_value.amt_credit_req_last_day\").cast(FloatType()).alias(\"amt_credit_req_last_day\"),\n",
    "    F.col(\"unnested_value.amt_credit_req_last_week\").cast(FloatType()).alias(\"amt_credit_req_last_week\"),\n",
    "    F.col(\"unnested_value.amt_credit_req_last_month\").cast(FloatType()).alias(\"amt_credit_req_last_month\"),\n",
    "    F.col(\"unnested_value.amt_credit_req_last_quarter\").cast(FloatType()).alias(\"amt_credit_req_last_quarter\"),\n",
    "    F.col(\"unnested_value.amt_credit_req_last_year\").cast(FloatType()).alias(\"amt_credit_req_last_year\"),\n",
    "    F.col(\"unnested_value.ts\").cast(\"timestamp\").alias(\"event_time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = df_formatted.writeStream\\\n",
    "           .format(\"console\")\\\n",
    "           .outputMode(\"append\")\\\n",
    "           .trigger(processingTime= \"5 seconds\")\\\n",
    "           .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Join the static data frames with the streaming data frame, perform data type/column conversion according to your ML model and print out the Schema. (Again, you can reuse code from 2A).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code reused from 2 A\n",
    "df_formatted = df_formatted\\\n",
    "                .withColumn(\"loan_to_income_ratio\", F.round(F.col(\"amt_credit\") / F.col(\"income_total\"),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bucket (age):\n",
    "    if age < 25:\n",
    "        return \"Y\"\n",
    "    elif age < 35:\n",
    "        return \"E\" \n",
    "    elif age< 45:\n",
    "        return \"M\"\n",
    "    elif age < 55:\n",
    "        return \"L\"\n",
    "    elif age< 65:\n",
    "        return \"N\"\n",
    "    else :\n",
    "        return \"R\"\n",
    "\n",
    "age_bucket_udf = F.udf(age_bucket, StringType())\n",
    "\n",
    "df_formatted = df_formatted.withColumn(\"age\", F.floor(F.abs(F.col(\"days_birth\"))/365.25)) \\\n",
    "    .withColumn(\"age_bucket\", age_bucket_udf(F.col(\"age\")))\\\n",
    "    .drop(\"age\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_worthiness(score):\n",
    "    if score >= 0.7:\n",
    "        return \"high\"\n",
    "    elif score >= 0.4:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "    \n",
    "udf_credit_worthiness = F.udf(credit_worthiness, StringType())\n",
    "\n",
    "colum_fill_null = ['credit_score_1','credit_score_2','credit_score_3']\n",
    "for columnName in colum_fill_null:\n",
    "    df_formatted = df_formatted.withColumn(columnName, F.coalesce(F.col(columnName), F.lit(0.5)))\n",
    "\n",
    "df_formatted = df_formatted.withColumn(\"credit_worthiness\", \n",
    "                       (F.col(\"credit_score_1\") + F.col(\"credit_score_2\") + F.col(\"credit_score_3\"))/3)\\\n",
    "                        .withColumn(\"credit_worthiness\", udf_credit_worthiness(F.col(\"credit_worthiness\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev_app = pre_data.groupBy(\"id_app\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_of_prev_app\"),\n",
    "        F.sum(F.when(F.col(\"name_contract_status\") == \"Approved\", 1).otherwise(0)).alias(\"num_of_approved_app\"),\n",
    "        F.sum(F.when(F.col(\"name_contract_status\") == \"Approved\", F.col(\"amt_credit\")).otherwise(0)).alias(\"total_credit\")\n",
    "    )\n",
    "\n",
    "df_joined = df_formatted.join(df_prev_app, \"id_app\", how = \"left\")\n",
    "# Replace null value with 0, because we still need to do the prediction if a new customer applies for a loan.\n",
    "need_fill_null = [\"num_of_prev_app\",\"num_of_approved_app\",\"total_credit\"]\n",
    "for columnName in need_fill_null:\n",
    "    df_joined = df_joined\\\n",
    "                            .withColumn(columnName, F.coalesce(F.col(columnName), F.lit(0)))\n",
    "df_joined = df_joined\\\n",
    "                        .withColumn(\"total_credit_to_income_ratio\", F.col(\"total_credit\")/ F.col(\"income_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_to_key_map = spark.sparkContext.broadcast(\n",
    "    {(row['category'], str(row['value'])): row['key'] for row in value_dic_data.collect()}\n",
    ")\n",
    "\n",
    "def replace_value_with_key(category, column_value):\n",
    "    return value_to_key_map.value.get((category, str(column_value)), column_value)\n",
    "\n",
    "udf_replace_value_with_key = F.udf(replace_value_with_key, StringType())\n",
    "columns_to_replace = [\"education_type\", \"occupation_type\", \"income_type\", \"family_status\"]\n",
    "\n",
    "for column in columns_to_replace:\n",
    "    df_joined = df_joined\\\n",
    "                            .withColumn(column, udf_replace_value_with_key(F.lit(column), F.col(column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the necessary features I need for the model\n",
    "features = ['id_app','days_birth', 'loan_to_income_ratio', 'num_of_prev_app', 'num_of_approved_app', 'total_credit', 'total_credit_to_income_ratio', 'gender', 'own_car', 'own_property', 'income_type', 'education_type', 'family_status', 'occupation_type', 'age_bucket', 'credit_worthiness','event_time']\n",
    "df_joined = df_joined.select(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_app: integer (nullable = true)\n",
      " |-- days_birth: integer (nullable = true)\n",
      " |-- loan_to_income_ratio: double (nullable = true)\n",
      " |-- num_of_prev_app: long (nullable = false)\n",
      " |-- num_of_approved_app: long (nullable = false)\n",
      " |-- total_credit: double (nullable = false)\n",
      " |-- total_credit_to_income_ratio: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- own_car: string (nullable = true)\n",
      " |-- own_property: string (nullable = true)\n",
      " |-- income_type: string (nullable = true)\n",
      " |-- education_type: string (nullable = true)\n",
      " |-- family_status: string (nullable = true)\n",
      " |-- occupation_type: string (nullable = true)\n",
      " |-- age_bucket: string (nullable = true)\n",
      " |-- credit_worthiness: string (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load your ML model, and use the model and Spark to perform the following:  \n",
    "    a) Every 10 seconds, print the total number of applications and number of potential default applications (prediction = 1) in the last 1 minute.  \n",
    "    b) Every 15 seconds, show the total requested credit (sum of credit where default=0) in the last 15 seconds.  \n",
    "    c) Every 1 minute, show the top 10 largest loan applications with the potential of default.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6a\n",
    "model = PipelineModel.load(\"best_classification_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preditions = model.transform(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['id_app','days_birth', 'loan_to_income_ratio', \n",
    "            'num_of_prev_app', 'num_of_approved_app', \n",
    "            'total_credit', 'total_credit_to_income_ratio', \n",
    "            'gender', 'own_car', 'own_property', 'income_type', \n",
    "            'education_type', 'family_status', 'occupation_type', \n",
    "            'age_bucket', 'credit_worthiness',\"prediction\",'event_time']\n",
    "preditions = preditions.select(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicantCounts = preditions \\\n",
    "    .withWatermark(\"event_time\", \"2 minutes\") \\\n",
    "    .groupBy(window(col(\"event_time\"), \"60 seconds\").alias(\"window\")) \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_num_applications\"),\n",
    "        sum(when(col(\"prediction\") == 1, 1).otherwise(0)).alias(\"num_potential_default_applications\")\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(applicantCounts.isStreaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query10 = applicantCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query10.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b\n",
    "windowedCreditSum = preditions \\\n",
    "    .withWatermark(\"event_time\", \"2 minutes\") \\\n",
    "    .groupBy(window(col(\"event_time\"), \"15 seconds\").alias(\"window\")) \\\n",
    "    .agg(\n",
    "        sum(when(col(\"prediction\") == 0, col(\"total_credit\")).otherwise(0)).alias(\"total_requested_credit\")\n",
    "    ) \\\n",
    "    .select(\"window\", \"total_requested_credit\")\n",
    "\n",
    "\n",
    "query11 = windowedCreditSum \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime=\"15 seconds\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "query11.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(windowedCreditSum.isStreaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------+----------+\n",
      "|event_time|id_app|total_credit|prediction|\n",
      "+----------+------+------------+----------+\n",
      "+----------+------+------------+----------+\n",
      "\n",
      "+-------------------+------+---------------+----------+\n",
      "|         event_time|id_app|   total_credit|prediction|\n",
      "+-------------------+------+---------------+----------+\n",
      "|2024-02-09 12:15:47|393110|      5730048.0|       1.0|\n",
      "|2024-02-09 12:15:47|393120|      3370752.0|       1.0|\n",
      "|2024-02-09 12:15:42|393097|      3269781.0|       1.0|\n",
      "|2024-02-09 12:15:42|393101|      2466747.0|       1.0|\n",
      "|2024-02-09 12:15:42|393091|2019128.8984375|       1.0|\n",
      "|2024-02-09 12:15:57|393145|      1242945.0|       1.0|\n",
      "|2024-02-09 12:15:52|393131|      1040868.0|       1.0|\n",
      "|2024-02-09 12:15:47|393112|       711886.5|       1.0|\n",
      "|2024-02-09 12:15:37|393080|       547893.0|       1.0|\n",
      "|2024-02-09 12:15:57|393140|       158625.0|       1.0|\n",
      "+-------------------+------+---------------+----------+\n",
      "\n",
      "+-------------------+------+------------+----------+\n",
      "|         event_time|id_app|total_credit|prediction|\n",
      "+-------------------+------+------------+----------+\n",
      "|2024-02-09 12:16:17|393222|   3219025.5|       1.0|\n",
      "|2024-02-09 12:16:27|393263|   2823502.5|       1.0|\n",
      "|2024-02-09 12:16:47|393345|   2745589.5|       1.0|\n",
      "|2024-02-09 12:16:02|393154|   2561449.5|       1.0|\n",
      "|2024-02-09 12:16:52|393364|   2560131.0|       1.0|\n",
      "|2024-02-09 12:16:27|393255|   2131542.0|       1.0|\n",
      "|2024-02-09 12:16:17|393235|   2042815.5|       1.0|\n",
      "|2024-02-09 12:16:47|430684|   1999152.0|       1.0|\n",
      "|2024-02-09 12:16:57|393379|   1913733.0|       1.0|\n",
      "|2024-02-09 12:16:12|393210|   1848685.5|       1.0|\n",
      "+-------------------+------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6c\n",
    "def process_batch(df, epoch_id):\n",
    "    df.filter(\"prediction = 1\") \\\n",
    "      .orderBy(desc(\"total_credit\")) \\\n",
    "      .limit(10) \\\n",
    "      .select(\"event_time\",\"id_app\",\"total_credit\", \"prediction\")\\\n",
    "      .show() \n",
    "\n",
    "query12 = preditions \\\n",
    "    .withWatermark(\"event_time\", \"1 minutes\") \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .trigger(processingTime='1 minute') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query12.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a Parquet file to store the following data:  \n",
    "    a) Persist the raw data: Persist your prediction results along with application data and event_time in Parquet format; after that, read the Parquet file and show the first 10 records.  \n",
    "    b) Persist the 15-second requested credit (6b) in another parquet file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 a\n",
    "# Persist the raw data\n",
    "persist_7a = preditions.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"path\", \"parquet/7a\")\\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/persist_7a\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_7a = StructType([\n",
    "    StructField(\"id_app\", IntegerType(), True),\n",
    "    StructField(\"days_birth\", IntegerType(), True),\n",
    "    StructField(\"loan_to_income_ratio\", DoubleType(), True),\n",
    "    StructField(\"num_of_prev_app\", LongType(), False),\n",
    "    StructField(\"num_of_approved_app\", LongType(), False),\n",
    "    StructField(\"total_credit\", DoubleType(), False),\n",
    "    StructField(\"total_credit_to_income_ratio\", DoubleType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"own_car\", StringType(), True),\n",
    "    StructField(\"own_property\", StringType(), True),\n",
    "    StructField(\"income_type\", StringType(), True),\n",
    "    StructField(\"education_type\", StringType(), True),\n",
    "    StructField(\"family_status\", StringType(), True),\n",
    "    StructField(\"occupation_type\", StringType(), True),\n",
    "    StructField(\"age_bucket\", StringType(), True),\n",
    "    StructField(\"credit_worthiness\", StringType(), True),\n",
    "    StructField(\"prediction\", DoubleType(), False),\n",
    "    StructField(\"event_time\", TimestampType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use this way to read due to I have to show the first 10 records\n",
    "predic_df = spark.read.parquet(\"parquet/7a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------\n",
      " id_app                       | 393890               \n",
      " days_birth                   | -13464               \n",
      " loan_to_income_ratio         | 2.77                 \n",
      " num_of_prev_app              | 2                    \n",
      " num_of_approved_app          | 1                    \n",
      " total_credit                 | 406786.5             \n",
      " total_credit_to_income_ratio | 1.80794              \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | N                    \n",
      " income_type                  | Working              \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Single / not married \n",
      " occupation_type              | Managers             \n",
      " age_bucket                   | M                    \n",
      " credit_worthiness            | medium               \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:27  \n",
      "-RECORD 1--------------------------------------------\n",
      " id_app                       | 393898               \n",
      " days_birth                   | -10944               \n",
      " loan_to_income_ratio         | 4.4                  \n",
      " num_of_prev_app              | 2                    \n",
      " num_of_approved_app          | 2                    \n",
      " total_credit                 | 184513.5             \n",
      " total_credit_to_income_ratio | 1.8637727272727274   \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | N                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Married              \n",
      " occupation_type              | Sales staff          \n",
      " age_bucket                   | E                    \n",
      " credit_worthiness            | low                  \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:27  \n",
      "-RECORD 2--------------------------------------------\n",
      " id_app                       | 393871               \n",
      " days_birth                   | -19562               \n",
      " loan_to_income_ratio         | 2.0                  \n",
      " num_of_prev_app              | 5                    \n",
      " num_of_approved_app          | 2                    \n",
      " total_credit                 | 399667.5             \n",
      " total_credit_to_income_ratio | 4.44075              \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | Y                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Single / not married \n",
      " occupation_type              | Sales staff          \n",
      " age_bucket                   | L                    \n",
      " credit_worthiness            | medium               \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:17  \n",
      "-RECORD 3--------------------------------------------\n",
      " id_app                       | 393879               \n",
      " days_birth                   | -12752               \n",
      " loan_to_income_ratio         | 6.9                  \n",
      " num_of_prev_app              | 6                    \n",
      " num_of_approved_app          | 5                    \n",
      " total_credit                 | 419859.0             \n",
      " total_credit_to_income_ratio | 3.8082448979591836   \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | Y                    \n",
      " income_type                  | State servant        \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Married              \n",
      " occupation_type              | Core staff           \n",
      " age_bucket                   | E                    \n",
      " credit_worthiness            | low                  \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:22  \n",
      "-RECORD 4--------------------------------------------\n",
      " id_app                       | 393889               \n",
      " days_birth                   | -14866               \n",
      " loan_to_income_ratio         | 4.0                  \n",
      " num_of_prev_app              | 1                    \n",
      " num_of_approved_app          | 1                    \n",
      " total_credit                 | 87966.0              \n",
      " total_credit_to_income_ratio | 0.3490714285714286   \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | Y                    \n",
      " income_type                  | Working              \n",
      " education_type               | Higher education     \n",
      " family_status                | Single / not married \n",
      " occupation_type              | Core staff           \n",
      " age_bucket                   | M                    \n",
      " credit_worthiness            | medium               \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:22  \n",
      "-RECORD 5--------------------------------------------\n",
      " id_app                       | 393835               \n",
      " days_birth                   | -12519               \n",
      " loan_to_income_ratio         | 0.42                 \n",
      " num_of_prev_app              | 13                   \n",
      " num_of_approved_app          | 12                   \n",
      " total_credit                 | 1901407.5            \n",
      " total_credit_to_income_ratio | 14.0845              \n",
      " gender                       | M                    \n",
      " own_car                      | Y                    \n",
      " own_property                 | Y                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Single / not married \n",
      " occupation_type              | Laborers             \n",
      " age_bucket                   | E                    \n",
      " credit_worthiness            | medium               \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:12  \n",
      "-RECORD 6--------------------------------------------\n",
      " id_app                       | 393816               \n",
      " days_birth                   | -12154               \n",
      " loan_to_income_ratio         | 5.0                  \n",
      " num_of_prev_app              | 7                    \n",
      " num_of_approved_app          | 6                    \n",
      " total_credit                 | 660528.0             \n",
      " total_credit_to_income_ratio | 3.6696               \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | Y                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Married              \n",
      " occupation_type              | Private service s... \n",
      " age_bucket                   | E                    \n",
      " credit_worthiness            | medium               \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:07  \n",
      "-RECORD 7--------------------------------------------\n",
      " id_app                       | 393825               \n",
      " days_birth                   | -8260                \n",
      " loan_to_income_ratio         | 0.67                 \n",
      " num_of_prev_app              | 1                    \n",
      " num_of_approved_app          | 1                    \n",
      " total_credit                 | 112554.0             \n",
      " total_credit_to_income_ratio | 0.41686666666666666  \n",
      " gender                       | M                    \n",
      " own_car                      | Y                    \n",
      " own_property                 | N                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Single / not married \n",
      " occupation_type              | (Empty)              \n",
      " age_bucket                   | Y                    \n",
      " credit_worthiness            | medium               \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:07  \n",
      "-RECORD 8--------------------------------------------\n",
      " id_app                       | 393848               \n",
      " days_birth                   | -10351               \n",
      " loan_to_income_ratio         | 2.44                 \n",
      " num_of_prev_app              | 1                    \n",
      " num_of_approved_app          | 1                    \n",
      " total_credit                 | 68742.0              \n",
      " total_credit_to_income_ratio | 0.61104              \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | Y                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Married              \n",
      " occupation_type              | Private service s... \n",
      " age_bucket                   | E                    \n",
      " credit_worthiness            | low                  \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:12  \n",
      "-RECORD 9--------------------------------------------\n",
      " id_app                       | 393827               \n",
      " days_birth                   | -20035               \n",
      " loan_to_income_ratio         | 4.0                  \n",
      " num_of_prev_app              | 5                    \n",
      " num_of_approved_app          | 2                    \n",
      " total_credit                 | 289498.5             \n",
      " total_credit_to_income_ratio | 2.144433333333333    \n",
      " gender                       | F                    \n",
      " own_car                      | N                    \n",
      " own_property                 | N                    \n",
      " income_type                  | Commercial associate \n",
      " education_type               | Secondary / secon... \n",
      " family_status                | Single / not married \n",
      " occupation_type              | (Empty)              \n",
      " age_bucket                   | L                    \n",
      " credit_worthiness            | low                  \n",
      " prediction                   | 0.0                  \n",
      " event_time                   | 2024-02-09 12:19:07  \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic_df.show(10, vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7b\n",
    "# Persist the 15-second requested credit (6b)\n",
    "persist_7b = windowedCreditSum \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"path\", \"parquet/7b\")\\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/persist_7b\")\\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Read the two parquet files from 7a and 7b as a data stream, and send the records to two topics with appropriate names.  \n",
    "(Note: You shall read the parquet files as a streaming data frame and send messages to the Kafka topic when new data appears in the parquet files. The parquet files serve as an intermediate storage in this use case.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 6a data I can use for part3 directly. This is the reason why I do this operation here. \n",
    "parquet_6a = applicantCounts.writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"path\", \"parquet/6a\")\\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/parquet_6a\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_6a = StructType([\n",
    "    StructField(\"window\", StructType([\n",
    "        StructField(\"start\", TimestampType(), True),\n",
    "        StructField(\"end\", TimestampType(), True),\n",
    "    ]), False),\n",
    "    StructField(\"total_num_applications\", LongType(), False),\n",
    "    StructField(\"num_potential_default_applications\", LongType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6a = spark.readStream\\\n",
    "        .format(\"parquet\")\\\n",
    "        .schema(schema_6a)\\\n",
    "        .load(\"parquet/6a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostip = \"host.docker.internal\"\n",
    "query6a_to_kafka = df_6a \\\n",
    "    .select(to_json(struct(\"*\")).alias(\"value\")) \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f'{hostip}:9092') \\\n",
    "    .option(\"topic\", \"topic_8a1\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/topic_8a1\") \\\n",
    "    .trigger(processingTime= \" 5 seconds\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also do the  parquet files from 7a \n",
    "df_8a = spark.readStream\\\n",
    "        .format(\"parquet\")\\\n",
    "        .schema(schema_7a)\\\n",
    "        .load(\"parquet/7a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostip = \"host.docker.internal\"\n",
    "query8a_to_kafka = df_8a \\\n",
    "    .select(to_json(struct(\"*\")).alias(\"value\")) \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f'{hostip}:9092') \\\n",
    "    .option(\"topic\", \"topic_8a2\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/topic_8a2\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_7b = StructType([\n",
    "    StructField(\"window\", StructType([\n",
    "        StructField(\"start\", TimestampType(), True),\n",
    "        StructField(\"end\", TimestampType(), True)\n",
    "    ]), False),\n",
    "    StructField(\"total_requested_credit\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "df_8b = spark.readStream\\\n",
    "        .format(\"parquet\")\\\n",
    "        .schema(schema_7b)\\\n",
    "        .load(\"parquet/7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostip = \"host.docker.internal\"\n",
    "query_8b_to_kafka = df_8b \\\n",
    "    .select(to_json(struct(\"*\")).alias(\"value\")) \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f'{hostip}:9092') \\\n",
    "    .option(\"topic\", \"topic_8b\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoint/topic_8b\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part just for testing if sending to kafka server successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'topic_8a1'\n",
    "#configuration\n",
    "hostip = \"host.docker.internal\"\n",
    "\n",
    "df_test = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", f\"{hostip}:9092\") \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = df_test\\\n",
    "            .writeStream\\\n",
    "            .outputMode(\"append\")\\\n",
    "            .format(\"console\")\\\n",
    "            .trigger(processingTime= \"5 seconds\")\\\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
